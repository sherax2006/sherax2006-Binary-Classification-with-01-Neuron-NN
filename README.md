This project implements a single-neuron neural network for binary classification using the sigmoid activation function. The model is trained using gradient descent, and training and validation loss curves are plotted to analyze whether the model is underfitting, overfitting, or showing well-behaved training.

The main objective of this project is to implement and understand the concepts of forward propagation and backward propagation in neural networks to learn optimal weights.

Features:
01: Forward propagation using sigmoid activation
02: Backward propagation with binary cross-entropy loss
03: Weight and bias updates using gradient descent
04: Training and validation loss curves
05: Accuracy evaluation on test data

Output:
01: Training loss per epoch
02: Validation loss per epoch
03: Test accuracy
04: Training vs Validation loss plot
